hpo_config:

  load_if_exists: True # this should set to True if hpo is run in parallel
  objective: [exponentiated_rmse] # [other metrics defined in base_experiment.py]
  objective_bounds: [[0.0, 1.0]] # [bounds for each objective]. Worse value will be assigned if objective evaluation is None
  direction: [maximize] # [minimize, maximize]
  repetitions: 5 # number of samples of performance for each objective query
  n_episodes: 5 # number of episodes to evaluate each policy
  use_gpu: True
  seed: 24
  save_n_best_hps: 1
  # budget
  trials: 40

  # hyperparameters
  hps_config:
    # model args
    hidden_dim: 64
    activation: relu

    # loss args
    gamma: 0.99
    gae_lambda: 0.95
    clip_param: 0.2
    target_kl: 0.01
    entropy_coef: 0.01

    # optim args
    opt_epochs: 10
    mini_batch_size: 64
    actor_lr: 0.0003
    critic_lr: 0.001

    # runner args
    max_env_steps: 72000

    # objective
    rew_state_weight: [1, 1, 1, 1]
    rew_act_weight: [0.1]
