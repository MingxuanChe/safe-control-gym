{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rollouts(notebook_dir, data_folder, controller_name, additional=''):\n",
    "    # print('notebook_dir', notebook_dir)\n",
    "    data_folder_path = os.path.join(notebook_dir, controller_name, data_folder)\n",
    "    # print('data_folder_path', data_folder_path)\n",
    "    assert os.path.exists(data_folder_path), 'data_folder_path does not exist'\n",
    "\n",
    "    # find all the subfolders in the data_folder_path\n",
    "    subfolders = [f.path for f in os.scandir(data_folder_path) if f.is_dir()]\n",
    "    # print('subfolders', subfolders)\n",
    "    # load the row 'rmse in the metrics.txt\n",
    "    metrics = []\n",
    "    traj_resutls = []\n",
    "    timing_data = []\n",
    "    for subfolder in subfolders:\n",
    "        file_path = os.path.join(subfolder, 'metrics.txt')\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if not line.startswith('rmse_std') and line.startswith('rmse'):\n",
    "                    # split the text between : and \\n\n",
    "                    line = line.split(': ')[-1].split('\\n')[0]\n",
    "                    metrics.append(eval(line))\n",
    "                if line.startswith('avarage_inference_time'):\n",
    "                    line = line.split(': ')[-1].split('\\n')[0]\n",
    "                    timing_data.append(eval(line))\n",
    "\n",
    "        # find the file ends with pickle and get the data\n",
    "        for file in os.listdir(subfolder):\n",
    "            if file.endswith('.pkl'):\n",
    "                file_path = os.path.join(subfolder, file)\n",
    "                # print('file_path', file_path)\n",
    "                results = np.load(file_path, allow_pickle=True)\n",
    "                traj_data = results['trajs_data']['obs'][0]\n",
    "                traj_resutls.append(traj_data)\n",
    "\n",
    "    traj_resutls = np.array(traj_resutls)\n",
    "    traj_file_name = f'traj_results_{controller_name}{additional}.npy'\n",
    "    np.save(traj_file_name, traj_resutls)\n",
    "    print('traj_results.shape', traj_resutls.shape)\n",
    "    # print('metrics', metrics)\n",
    "    rmse_mean_mpc = np.mean(metrics)\n",
    "    rmse_std_mpc = np.std(metrics)\n",
    "    print(f'rmse_{controller_name}{additional}', rmse_mean_mpc, rmse_std_mpc)\n",
    "    return traj_resutls, metrics, timing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.patches import Polygon\n",
    "def plot_xz_trajectory_with_hull(ax, traj_data, label=None, \n",
    "                                 traj_color='skyblue', hull_color='lightblue',\n",
    "                                 alpha=0.5, padding_factor=1.1):\n",
    "    '''Plot trajectories with convex hull showing variance over seeds.\n",
    "    \n",
    "    Args:\n",
    "        ax (Axes): Matplotlib axes.\n",
    "        traj_data (np.ndarray): Trajectory data of shape (num_seeds, num_steps, 6).\n",
    "        padding_factor (float): Padding factor for the convex hull.\n",
    "    '''\n",
    "    num_seeds, num_steps, _ = traj_data.shape\n",
    "\n",
    "    print('traj data shape:', traj_data.shape)\n",
    "    mean_traj = np.mean(traj_data, axis=0)\n",
    "    \n",
    "    ax.plot(mean_traj[:, 0], mean_traj[:, 2], color=traj_color, label=label)\n",
    "    # plot the hull\n",
    "    for i in range(num_steps - 1):\n",
    "        # plot the hull at a single step\n",
    "        points_at_step = traj_data[:, i, [0, 2]]\n",
    "        hull = ConvexHull(points_at_step)\n",
    "        cent = np.mean(points_at_step, axis=0) # center\n",
    "        pts = points_at_step[hull.vertices] # vertices\n",
    "        poly = Polygon(padding_factor*(pts - cent) + cent, \n",
    "                       closed=True,  \n",
    "                       capstyle='round', \n",
    "                       facecolor=hull_color,\n",
    "                       alpha=alpha)\n",
    "        ax.add_patch(poly)\n",
    "\n",
    "        # connecting consecutive convex hulls\n",
    "        points_at_next_step = traj_data[:, i+1, [0, 2]]\n",
    "        points_connecting = np.concatenate([points_at_step, points_at_next_step], axis=0)\n",
    "        hull_connecting = ConvexHull(points_connecting)\n",
    "        cent_connecting = np.mean(points_connecting, axis=0)\n",
    "        pts_connecting = points_connecting[hull_connecting.vertices]\n",
    "        poly_connecting = Polygon(padding_factor*(pts_connecting - cent_connecting) + cent_connecting, \n",
    "                                  closed=True,  \n",
    "                                  capstyle='round', \n",
    "                                  facecolor=hull_color,\n",
    "                                  alpha=alpha)\n",
    "        ax.add_patch(poly_connecting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rollouts(additional='' ):\n",
    "    import mb_experiment_rollout\n",
    "    start_seed = 10\n",
    "    num_seed = 10\n",
    "    algo = 'pid'\n",
    "    num_runs_per_seed = 1\n",
    "\n",
    "    for seed in range(start_seed, num_seed + start_seed):\n",
    "        for _ in range(num_runs_per_seed):\n",
    "            mb_experiment_rollout.run(seed=seed, Additional=additional, ALGO=algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(notebook_dir, data_folder, title):\n",
    "    from safe_control_gym.utils.configuration import ConfigFactory\n",
    "    from functools import partial\n",
    "    from safe_control_gym.utils.registration import make\n",
    "    #########################################################################\n",
    "    # launch SCG to get reference trajectory X_GOAL\n",
    "    ALGO = 'pid'\n",
    "    SYS = 'quadrotor_2D_attitude'\n",
    "    TASK = 'tracking'\n",
    "    # PRIOR = '200_hpo'\n",
    "    PRIOR = '100'\n",
    "    agent = 'quadrotor' if SYS == 'quadrotor_2D' or SYS == 'quadrotor_2D_attitude' else SYS\n",
    "    SAFETY_FILTER = None\n",
    "\n",
    "    # check if the config file exists\n",
    "    assert os.path.exists(f'./config_overrides/{SYS}_{TASK}.yaml'), f'../config_overrides/{SYS}_{TASK}.yaml does not exist'\n",
    "    assert os.path.exists(f'./config_overrides/{ALGO}_{SYS}_{TASK}_{PRIOR}.yaml'), f'../config_overrides/{ALGO}_{SYS}_{TASK}_{PRIOR}.yaml does not exist'\n",
    "    if SAFETY_FILTER is None:\n",
    "        sys.argv[1:] = ['--algo', ALGO,\n",
    "                        '--task', agent,\n",
    "                        '--overrides',\n",
    "                            f'./config_overrides/{SYS}_{TASK}.yaml',\n",
    "                            f'./config_overrides/{ALGO}_{SYS}_{TASK}_{PRIOR}.yaml',\n",
    "                        '--seed', '2',\n",
    "                        '--use_gpu', 'True',\n",
    "                        '--output_dir', f'./{ALGO}/results',\n",
    "                            ]\n",
    "    fac = ConfigFactory()\n",
    "    fac.add_argument('--func', type=str, default='train', help='main function to run.')\n",
    "    fac.add_argument('--n_episodes', type=int, default=1, help='number of episodes to run.')\n",
    "    # merge config and create output directory\n",
    "    config = fac.merge()\n",
    "    # Create an environment\n",
    "    env_func = partial(make,\n",
    "                        config.task,\n",
    "                        seed=config.seed,\n",
    "                        **config.task_config\n",
    "                        )\n",
    "    random_env = env_func(gui=False)\n",
    "    X_GOAL = random_env.X_GOAL\n",
    "    ##########################################################################\n",
    "    # load trajectory pkl files, load from folder\n",
    "    controller_name = 'pid'\n",
    "    fmpc_data_path = os.path.join(notebook_dir, controller_name, data_folder)\n",
    "    assert os.path.exists(fmpc_data_path), 'data_folder_path does not exist'\n",
    "    # fmpc_data_path = '/home/tobias/Studium/masterarbeit/code/safe-control-gym/benchmarking_sim/quadrotor/fmpc/results_rollout/temp'\n",
    "    fmpc_data_dirs = [d for d in os.listdir(fmpc_data_path) if os.path.isdir(os.path.join(fmpc_data_path, d))]\n",
    "    fmpc_traj_data_name = f'{controller_name}_data_quadrotor_traj_tracking.pkl'\n",
    "    fmpc_traj_data_name = [os.path.join(d, fmpc_traj_data_name) for d in fmpc_data_dirs]\n",
    "\n",
    "    fmpc_data = []\n",
    "    for d in fmpc_traj_data_name:\n",
    "        fmpc_data.append(np.load(os.path.join(fmpc_data_path, d), allow_pickle=True))\n",
    "    fmpc_traj_data = [d['trajs_data']['obs'][0] for d in fmpc_data]\n",
    "    fmpc_traj_data = np.array(fmpc_traj_data)\n",
    "    print(fmpc_traj_data.shape) # seed, time_step, obs\n",
    "    # take average of all seeds\n",
    "    mpc_mean_traj_data = np.mean(fmpc_traj_data, axis=0)\n",
    "    print(mpc_mean_traj_data.shape) # (mean_541, 6)\n",
    "\n",
    "\n",
    "    # Define Colors\n",
    "    ref_color = 'black'\n",
    "    fmpc_color = 'purple'\n",
    "    fmpc_hull_color = 'violet'\n",
    "\n",
    "    # plot the state path x, z [0, 2]\n",
    "    title_fontsize = 20\n",
    "    legend_fontsize = 14\n",
    "    axis_label_fontsize = 14\n",
    "    axis_tick_fontsize = 12\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    # adjust the distance between title and the plot\n",
    "    fig.subplots_adjust(top=0.2)\n",
    "    ax.plot(X_GOAL[:, 0], X_GOAL[:, 2], color=ref_color, linestyle='-.', label='Reference')\n",
    "    # ax.plot()\n",
    "    ax.set_xlabel('$x$ [m]', fontsize=axis_label_fontsize)\n",
    "    ax.set_ylabel('$z$ [m]', fontsize=axis_label_fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=axis_tick_fontsize)\n",
    "    # ax.set_title('State path in $x$-$z$ plane')\n",
    "    # set the super title\n",
    "    # if not generalization:\n",
    "    #     fig.suptitle(f'Evaluation ({plot_name})', fontsize=title_fontsize)\n",
    "    # else:\n",
    "    #     fig.suptitle(f'Generalization ({plot_name})', fontsize=title_fontsize)\n",
    "    fig.suptitle(title, fontsize=title_fontsize)\n",
    "    ax.set_ylim(0.35, 1.85)\n",
    "    ax.set_xlim(-1.6, 1.6)\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    # plot the convex hull of each steps\n",
    "    k = 1.1 # padding factor\n",
    "    alpha = 0.2\n",
    "\n",
    "    plot_xz_trajectory_with_hull(ax, fmpc_traj_data, label='FMPC',\n",
    "                                    traj_color=fmpc_color, hull_color=fmpc_hull_color,\n",
    "                                    alpha=alpha, padding_factor=k)\n",
    "\n",
    "    ax.legend(ncol=5, loc='upper center', fontsize=legend_fontsize)\n",
    "\n",
    "    fig.savefig(os.path.join(fmpc_data_path, 'xz_path_performance.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run FMPC Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "print('notebook_dir', notebook_dir)\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "s = 2 # times of std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additionals_list = ['']\n",
    "additionals_list = ['', '_slow', '_fast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for additional in additionals_list:\n",
    "    run_rollouts(additional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get mean rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = 'pid'\n",
    "# for additional in additionals_list:\n",
    "#     data_folder = f'results_rollout{additional}/temp'\n",
    "#     traj_resutls, metrics = extract_rollouts(notebook_dir, data_folder, ctrl, additional)\n",
    "\n",
    "additional = ''\n",
    "data_folder = f'results_rollout{additional}/temp'\n",
    "traj_resutls, metrics, timing_data = extract_rollouts(notebook_dir, data_folder, ctrl, additional)\n",
    "sp_plot_perf = np.mean(metrics) # spider plot performance\n",
    "\n",
    "additional = '_slow'\n",
    "data_folder = f'results_rollout{additional}/temp'\n",
    "traj_resutls, metrics, _ = extract_rollouts(notebook_dir, data_folder, ctrl, additional)\n",
    "sp_plot_gen_slow = np.mean(metrics) # spider plot generalization performance slow\n",
    "\n",
    "additional = '_fast'\n",
    "data_folder = f'results_rollout{additional}/temp'\n",
    "traj_resutls, metrics, _ = extract_rollouts(notebook_dir, data_folder, ctrl, additional)\n",
    "sp_plot_gen_fast = np.mean(metrics) # spider plot generalization performance fast\n",
    "\n",
    "print('rmse_eval:', sp_plot_perf)\n",
    "print('rmse_slow:', sp_plot_gen_slow)\n",
    "print('rmse_fast:', sp_plot_gen_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate mean execution time --> Inference time in spider plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vector = (np.squeeze(timing_data)).flatten()\n",
    "mean_exec_time = np.mean(time_vector)\n",
    "max_exec_time = np.max(time_vector)\n",
    "print('Mean execution time:', mean_exec_time)\n",
    "print('Max execution time:', max_exec_time)\n",
    "sp_plot_inf_time = mean_exec_time # save for later, spider plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot execution time \n",
    "plt.figure()\n",
    "plt.plot(time_vector)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Trajectory with Hull - like slide 8\n",
    "\n",
    "Later this needs to be added to the other Model based algorithms, cannot do that right now as I don't have that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional = ''\n",
    "data_folder = f'results_rollout{additional}/temp'\n",
    "plot_trajectory(notebook_dir, data_folder, 'Evaluation')\n",
    "\n",
    "additional = '_slow'\n",
    "data_folder = f'results_rollout{additional}/temp'\n",
    "plot_trajectory(notebook_dir, data_folder, 'Generalization (slower)')\n",
    "\n",
    "additional = '_fast'\n",
    "data_folder = f'results_rollout{additional}/temp'\n",
    "plot_trajectory(notebook_dir, data_folder, 'Generalization (faster)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness\n",
    "\n",
    "### run robustness experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mb_experiment_noise\n",
    "seeds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "noise_factors = np.arange(0, 210, 10)\n",
    "# noise_factors = [1, 10, 20, 30, 40]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    for noise_fac in noise_factors:\n",
    "        mb_experiment_noise.run(seed=seed, noise_factor=noise_fac, ALGO=ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Robustness, adapted from plot_noise.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robustness evaluation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "controller = ctrl\n",
    "prior = 'results_noise'\n",
    "\n",
    "max_seed = 2\n",
    "max_seed = len(seeds)\n",
    "metric_name = 'metrics.txt'\n",
    "s = 2 # times std\n",
    "obs_dim = 6\n",
    "\n",
    "# get the default color cycle\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "plot_color = {'ilqr': 'gray', \n",
    "              'gpmpc_acados': colors[0], \n",
    "              'mpc_acados':colors[-1], \n",
    "              'linear_mpc':colors[2], \n",
    "              'fmpc': colors[4],\n",
    "              'pid': colors[5]\n",
    "              } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_folder_dir = f'./{controller}/{prior}/'\n",
    "# find the folder in the dir\n",
    "seed_data_folder = os.listdir(os.path.join(notebook_dir, data_folder_dir))\n",
    "print('seed_data_folder', seed_data_folder)\n",
    "seed_data_folder = [f for f in seed_data_folder if os.path.isdir(os.path.join(data_folder_dir, f))]\n",
    "seed_data_folder = sorted(seed_data_folder, key=lambda x: int(x.split('_')[1]))\n",
    "\n",
    "seed_data_folder = [os.path.join(data_folder_dir, f, 'temp') for f in seed_data_folder]\n",
    "print('seed_data_folder', seed_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for seed in range(0, max_seed):\n",
    "    results[repr(seed)] = {}\n",
    "    rmse_list = []\n",
    "    early_stop_list = []\n",
    "    noise_factor_list = []\n",
    "    traj_data_list = []\n",
    "    traj_steps_list = []\n",
    "    # fild runs\n",
    "    load_seed_dir = seed_data_folder[seed]\n",
    "    runs_data_folder = os.listdir(os.path.join(notebook_dir, load_seed_dir))\n",
    "    runs_data_folder = [os.path.join(load_seed_dir, f) for f in runs_data_folder]\n",
    "    # sort the runs\n",
    "    runs_data_folder = sorted(runs_data_folder)\n",
    "    print('runs_data_folder', runs_data_folder)\n",
    "    for runs in runs_data_folder:\n",
    "        # load the metric file in the folder\n",
    "        metric_file = os.path.join(runs, metric_name)\n",
    "        # print('metric_file', metric_file)\n",
    "        data = pd.read_csv(metric_file, delimiter=':')\n",
    "        # convert to numpy\n",
    "        data = data.to_numpy()\n",
    "        # print(data)\n",
    "        # convert to dictionary\n",
    "        data = {data[i][0]: data[i][1] for i in range(len(data))}\n",
    "\n",
    "        noise_factor = eval(data['noise_factor'])\n",
    "        rmse = eval(data['rmse'])\n",
    "        early_stop = eval(data['early_stop'])\n",
    "        rmse_list.append(rmse)\n",
    "        early_stop_list.append(early_stop)\n",
    "        noise_factor_list.append(noise_factor)\n",
    "\n",
    "        # load the traj\n",
    "        traj_file = os.path.join(runs, f'{controller}_data_quadrotor_traj_tracking.pkl')\n",
    "        traj_data = pd.read_pickle(traj_file)\n",
    "        traj_data = traj_data['trajs_data']['obs'][0]\n",
    "        traj_steps = len(traj_data)\n",
    "        traj_data_list.append(traj_data)\n",
    "        traj_steps = len(traj_data)\n",
    "        traj_steps_list.append(traj_steps)\n",
    "    \n",
    "    results[repr(seed)]['rmse'] = rmse_list\n",
    "    results[repr(seed)]['early_stop'] = early_stop_list\n",
    "    results[repr(seed)]['noise_factor'] = noise_factor_list\n",
    "    # results[repr(seed)]['traj_data'] = traj_data_list\n",
    "    results[repr(seed)]['traj_steps'] = traj_steps_list\n",
    "\n",
    "max_noise_factor = max([max(results[repr(seed)]['noise_factor']) for seed in range(max_seed)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "# x axis noise factor\n",
    "# y axis rmse\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for seed in range(max_seed):\n",
    "    ax.plot(results[repr(seed)]['noise_factor'], results[repr(seed)]['rmse'], label=f'seed_{seed+1}')\n",
    "    # check data length\n",
    "    print('seed:', seed, 'len:', len(results[repr(seed)]['rmse']))\n",
    "ax.set_xlabel('noise factor')\n",
    "ax.set_ylabel('rmse')\n",
    "ax.legend()\n",
    "fig.savefig(os.path.join(notebook_dir, f'{ctrl}/results_noise/noise_plot.png'), bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file_name = f'{notebook_dir}/data/noise_results_{controller}.npy'\n",
    "np.save(results_file_name, results)\n",
    "print(f'saved {notebook_dir}/{results_file_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stop\n",
    "num_noise_factor = len(results[repr(seed)]['noise_factor'])\n",
    "print('num_noise_factor', num_noise_factor)\n",
    "early_stop_results = [False for _ in range(num_noise_factor)]\n",
    "# print('early_stop_results', early_stop_results)\n",
    "# print('len(early_stop_results)', len(early_stop_results))\n",
    "for seed in range(max_seed):\n",
    "    for i in range(len(results[repr(seed)]['noise_factor'])):\n",
    "        early_stop_results[i] = early_stop_results[i] or results[repr(seed)]['early_stop'][i]\n",
    "print('early_stop_results', early_stop_results)\n",
    "# find the first early stop\n",
    "if True in early_stop_results:\n",
    "    first_early_stop = early_stop_results.index(True)\n",
    "    early_stop_noise_factor = results[repr(seed)]['noise_factor'][first_early_stop]\n",
    "    sp_plot_robustness = early_stop_noise_factor # later for spider plot\n",
    "else:\n",
    "    print('no early stop')\n",
    "    first_early_stop = None\n",
    "    early_stop_noise_factor = None\n",
    "    sp_plot_robustness = np.max(noise_factors) # later for spider plot\n",
    "print('first_early_stop', first_early_stop)\n",
    "print('early_stop_noise_factor', early_stop_noise_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite early stop if it does not stop early\n",
    "early_stop_noise_factor = sp_plot_robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_data = []\n",
    "for seed in range(max_seed):\n",
    "        print('seed', seed)\n",
    "        print(len(results[repr(seed)]['rmse']))\n",
    "        rmse_data.append(results[repr(seed)]['rmse'])\n",
    "\n",
    "# rmse_data = np.array(rmse_data)\n",
    "# rmse_data.shape\n",
    "np.array(rmse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mean_rmse = np.mean([results[repr(seed)]['rmse'] for seed in range(max_seed)], axis=0)\n",
    "std_rmse = np.std([results[repr(seed)]['rmse'] for seed in range(max_seed)], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 2))\n",
    "ax.plot(results[repr(seed)]['noise_factor'], mean_rmse, \n",
    "        label='mean', color=plot_color[controller])\n",
    "ax.fill_between(results[repr(seed)]['noise_factor'], mean_rmse- s*std_rmse, mean_rmse+ s*std_rmse, \n",
    "                alpha=0.2, label=f'{s} std', color=plot_color[controller])\n",
    "\n",
    "# plot shaded area for the first early stop\n",
    "ax.axvspan(early_stop_noise_factor, max_noise_factor, color='red', alpha=0.1, label='early stop')\n",
    "\n",
    "ax.set_xlim([1, max_noise_factor])\n",
    "ax.set_ylim([0, None])\n",
    "# explicitly show the tick from 1 to the max noise factor\n",
    "noise_ticks = [i for i in range(20, max_noise_factor+1, 20)]\n",
    "# append 1 at the beginning\n",
    "noise_ticks = [1] + noise_ticks\n",
    "ax.set_xticks(noise_ticks)\n",
    "# plot y line at 0.1\n",
    "ax.axhline(y=0.1, color='gray', linestyle='--', label='RMSE = 0.1')\n",
    "ax.legend(ncol=2)\n",
    "ax.set_xlabel('Noise amplification factor')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title(f'RMSE of {controller} with amplified noise')\n",
    "fig.savefig(os.path.join(notebook_dir, 'fmpc/results_noise/noise_plot2.png'), dpi=300, bbox_inches='tight')\n",
    "mean_rmse[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Spider Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all previously computed variables are computed\n",
    "sp_plot_perf\n",
    "sp_plot_gen_slow\n",
    "sp_plot_gen_fast\n",
    "sp_plot_robustness\n",
    "sp_plot_inf_time\n",
    "\n",
    "# manually set parameter\n",
    "sp_plot_model_knowledge = 3\n",
    "sp_plot_sampling_complex = 1\n",
    "\n",
    "print('performance', sp_plot_perf)\n",
    "print('generalization_slow', sp_plot_gen_slow)\n",
    "print('generalization_fast', sp_plot_gen_fast)\n",
    "print('robustness', sp_plot_robustness)\n",
    "print('sampling complex', sp_plot_sampling_complex)\n",
    "print('model knowledge', sp_plot_model_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking_sim.quadrotor.plotting.plot_radar import spider\n",
    "\n",
    "num_axis = 6\n",
    "gen_performance = [0.07240253210609013, 0.031425261835490235,  # GP-MPC\n",
    "                0.10363015782869267, 0.03574250675445726,  # Linear-MPC\n",
    "                0.06669989755434953, 0.023313325828377546,  # MPC\n",
    "                0.049631400535807925, 0.047894774207991445,  # PPO\n",
    "                0.12754716185055215, 0.08743083392874743,  # SAC\n",
    "                0.050426782816096215, 0.04861203156962396,  # DPPO\n",
    "                sp_plot_gen_slow, sp_plot_gen_fast,  # FMPC\n",
    "\n",
    "                ]\n",
    "performance = [0.049872511450839645, 0.049872511450839645,  # GP-MPC\n",
    "            0.06556989411791102, 0.06556989411791102,  # Linear-MPC\n",
    "            0.04421752503119518, 0.04421752503119518,  # MPC\n",
    "            0.01746153113470009, 0.01746153113470009,  # PPO\n",
    "            0.0764178745409007, 0.0764178745409007,  # SAC\n",
    "            0.01931011838369746, 0.01931011838369746,  # DPPO\n",
    "            sp_plot_perf, sp_plot_perf,  # FMPC\n",
    "            ]\n",
    "inference_time = [0.0090775150246974736, 0.0090775150246974736,\n",
    "                0.0011251235, 0.0011251235,\n",
    "                0.0061547613, 0.0061547613,\n",
    "                0.00020738168999000832, 0.00020738168999000832,\n",
    "                0.00024354409288477016, 0.00024354409288477016,\n",
    "                0.0001976909460844817, 0.0001976909460844817,\n",
    "                sp_plot_inf_time, sp_plot_inf_time,  # FMPC\n",
    "                ]\n",
    "model_complexity = [80, 80,\n",
    "                    40, 40,\n",
    "                    80, 80,\n",
    "                    1, 1,\n",
    "                    1, 1,\n",
    "                    1, 1,\n",
    "                    80, 80]\n",
    "sampling_complexity = [int(660), int(660),\n",
    "                    int(1), int(1),\n",
    "                    int(1), int(1),\n",
    "                    int(2.8 * 1e5), int(2.8 * 1e5),\n",
    "                    int(2 * 1e5), int(2 * 1e5),\n",
    "                    int(2.5 * 1e5), int(2.5 * 1e5),\n",
    "                    int(1), int(1)]\n",
    "robustness = [120, 120,\n",
    "            90, 90,\n",
    "            90, 90,\n",
    "            10, 10,\n",
    "            30, 30,\n",
    "            20, 20, \n",
    "            sp_plot_robustness, sp_plot_robustness]\n",
    "data = [gen_performance, performance, inference_time, model_complexity, sampling_complexity, robustness]\n",
    "max_values = [0.01, 0.01, 1e-5, 1, 1, 120]\n",
    "min_values = [0.2, 0.2, 1e-2, 80, 3.e5, 1]\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    data[i].append(max_values[i])\n",
    "    data[i].append(min_values[i])\n",
    "\n",
    "# append the max and min values to the data\n",
    "algos = ['GP-MPC', 'GP-MPC',\n",
    "        'Linear MPC', 'Linear MPC',\n",
    "        'Nonlinear MPC', 'Nonlinear MPC',\n",
    "        'PPO', 'PPO',\n",
    "        'SAC', 'SAC',\n",
    "        'DPPO', 'DPPO',\n",
    "        'FMPC', 'FMPC',\n",
    "        'MAX', 'MIN']\n",
    "    # apppend the max and min values to the data\n",
    "\n",
    "\n",
    "masks_algo = [12, 13, -2, -1] #FMPC\n",
    "#masks_algo = [0, 1, -2, -1] #GPMPC\n",
    "data = np.array(data)[:, masks_algo]\n",
    "data = data.tolist()\n",
    "algos = [algos[i] for i in masks_algo]\n",
    "print(algos)\n",
    "\n",
    "spider(\n",
    "    pd.DataFrame({\n",
    "        # 'x': [*'ab'],\n",
    "        'x': algos,\n",
    "        '$\\qquad\\qquad\\qquad\\quad$  Generalization\\n $\\qquad\\qquad\\qquad\\quad$ performance\\n\\n':\n",
    "            data[0],\n",
    "        '$\\qquad\\qquad\\qquad\\quad$ Performance\\n':\n",
    "            data[1],\n",
    "        # '$\\quad\\quad\\quad\\quad\\quad\\qquad$(Figure-8 tracking)': [3.94646538e-02, 0.03],\n",
    "        'Inference\\ntime\\n\\n':\n",
    "            data[2],\n",
    "        'Model                \\nknowledge                ':\n",
    "            [int(data[3][i]) for i in range(len(data[3]))],\n",
    "        '\\n\\n\\nSampling\\ncomplexity':\n",
    "            data[4],\n",
    "        '\\n\\nRobustness':\n",
    "            [int(data[5][i]) for i in range(len(data[5]))],\n",
    "    }),\n",
    "\n",
    "    id_column='x',\n",
    "    # title='   Overall Comparison',\n",
    "    # title = algos[0],\n",
    "    title=None,\n",
    "    # subtitle='(Normalized linear scale)',\n",
    "    padding=1.1,\n",
    "    # padding=1,\n",
    "    plt_name=algos[0],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
